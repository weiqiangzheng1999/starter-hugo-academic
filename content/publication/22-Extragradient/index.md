---
title: Tight Last-iterate Convergence of the Extragradient Method in Constrained
  Monotone Variational Inequalities
publication_types:
  - "3"
authors:
  - yang-cai
  - argyris-oikonomou
  - admin
author_notes: []
publication: Working Paper
publication_short: Working Paper
abstract: "  The monotone variational inequality is a central problem in
  mathematical programming that unifies and generalizes many important settings
  such as smooth convex optimization, two player zero-sum games, convex-concave
  saddle point problems, etc. The extragradient method by Korpelevich [1976] is
  one of the most popular methods for solving monotone variational inequalities.
  Despite its long history and intensive attention from the optimization and
  machine learning community, the following major problem remains open. What is
  the last-iterate convergence rate of the extragradient method for monotone and
  Lipschitz variational inequalities with constraints? We resolve this open
  problem by showing a tight O(1/\\sqrt{T}) last-iterate convergence rate for
  arbitrary convex feasible sets, which matches the lower bound by Golowich et
  al. [2020]. Our rate is measured in terms of the standard gap function. The
  technical core of our result is the monotonicity of a new performance measure
  â€“ the tangent residual, which can be viewed as an adaptation of the norm of
  the operator that takes the local constraints into account. To establish the
  monotonicity, we develop a new approach that combines the power of the
  sum-of-squares programming with the low dimensionality of the update rule of
  the extragradient method. We believe our approach has many additional
  applications in the analysis of iterative methods."
draft: false
featured: false
links:
- name: arXiv
  url: https://arxiv.org/abs/2204.09228
image:
  filename: featured
  focal_point: Smart
  preview_only: false
date: 2022-04-22T00:25:30.534Z
---
